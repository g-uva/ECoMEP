# version: "3.9"

services:
  mqtt:
    image: eclipse-mosquitto:2
    container_name: mqtt
    ports:
      - "1883:1883"
    volumes:
      # make sure this file exists at repo root; see snippet below
      - ./mosquitto.conf:/mosquitto/config/mosquitto.conf:ro
    # healthcheck:Â 
    #   test: ["CMD-SHELL", "mosquitto_sub -h 127.0.0.1 -t test -C 1 -W 2 || exit 1"]
    #   interval: 10s
    #   timeout: 3s
    #   retries: 5
    restart: unless-stopped

  zookeeper:
    image: zookeeper:3.8
    container_name: zookeeper
    ports: ["2181:2181"]
    restart: unless-stopped

  kafka:
    image: bitnami/kafka:3.7
    container_name: kafka
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
      - ALLOW_PLAINTEXT_LISTENER=yes
    depends_on: [zookeeper]
    ports:
      - "9092:9092"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "/opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 12

  kafka-init:
    image: bitnami/kafka:3.7
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./kafka_streaming/topics.sh:/app/topics.sh:ro
    environment:
      - BOOTSTRAP=kafka:9092
      - KAFKA_BIN=/opt/bitnami/kafka/bin
    entrypoint: ["/bin/bash","-lc","bash /app/topics.sh"]
    restart: "no"


  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka_ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    depends_on: [kafka]
    restart: unless-stopped

  # The bridge containerised
  mqtt_to_kafka:
    build:
      context: ..
      dockerfile: streaming_service/kafka_streaming/Dockerfile
    container_name: mqtt_to_kafka
    environment:
      MQTT_BROKER: mqtt
      MQTT_PORT: 1883
      MQTT_TOPIC: ecc/metrics/#
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: metrics.raw.stream
    depends_on: [mqtt, kafka]
    restart: unless-stopped

  # # --- MinIO (S3-compatible store for Iceberg) ---
  # minio:
  #   image: minio/minio:latest
  #   command: server /data --console-address ":9001"
  #   environment:
  #     MINIO_ROOT_USER: minio
  #     MINIO_ROOT_PASSWORD: minio123
  #   ports: ["9000:9000", "9001:9001"]
  #   volumes:
  #     - ./minio-data:/data
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/ready"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 12
  #   restart: unless-stopped

  # # Create the 'warehouse' bucket once
  # mc:
  #   image: minio/mc:latest
  #   depends_on:
  #     minio:
  #       condition: service_healthy
  #   entrypoint: ["/bin/sh","-lc","mc alias set local http://minio:9000 minio minio123 && mc mb -p local/warehouse || true && tail -f /dev/null"]
  #   restart: unless-stopped


  # # --- Flink (SQL) ---
  # flink-jobmanager:
  #   image: flink:1.18
  #   command: jobmanager
  #   environment:
  #     - |
  #       FLINK_PROPERTIES=
  #       jobmanager.rpc.address: flink-jobmanager
  #       rest.address: 0.0.0.0
  #       rest.port: 8081
  #       # S3/MinIO for Iceberg
  #       s3.endpoint: http://minio:9000
  #       s3.path.style.access: true
  #       s3.access-key: minio
  #       s3.secret-key: minio123
  #       s3.ssl.enabled: false
  #   ports: ["8081:8081"]
  #   volumes:
  #     - ./flink-lib:/opt/flink/custom-lib
  #     - ./sql:/sql
  #   restart: unless-stopped

  # flink-taskmanager:
  #   image: flink:1.18
  #   command: taskmanager
  #   depends_on: [flink-jobmanager]
  #   environment:
  #     - |
  #       FLINK_PROPERTIES=
  #       classloader.resolve-order: parent-first
  #       jobmanager.rpc.address: flink-jobmanager
  #       taskmanager.numberOfTaskSlots: 2

  #       rest.address: 0.0.0.0
  #       rest.port: 8081
  #       pipeline.jars: file:///opt/flink/custom-lib/flink-connector-kafka-3.2.0-1.18.jar,file:///opt/flink/custom-lib/iceberg-flink-runtime-1.5.0.jar,file:///opt/flink/custom-lib/iceberg-aws-bundle-1.5.0.jar

  #       s3.endpoint: http://minio:9000
  #       s3.path.style.access: true
  #       s3.access-key: minio
  #       s3.secret-key: minio123
  #       s3.ssl.enabled: false
  #   volumes:
  #     - ./flink-lib:/opt/flink/custom-lib
  #   restart: unless-stopped

  # # Run the SQL once (detached) after JM is up
  # flink-sql-init:
  #   image: flink:1.18
  #   depends_on:
  #     flink-jobmanager:
  #       condition: service_started
  #   volumes:
  #     - ./flink-lib:/opt/flink/custom-lib
  #     - ./sql:/sql
  #   entrypoint: ["/bin/bash", "-lc", "bin/sql-client.sh -f /sql/flink_to_iceberg.sql"]
  #   restart: "no"
