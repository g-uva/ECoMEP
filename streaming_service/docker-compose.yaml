# version: "3.9"

services:
  mqtt:
    image: eclipse-mosquitto:2
    container_name: mqtt
    ports:
      - "1883:1883"
    volumes:
      # make sure this file exists at repo root; see snippet below
      - ./mosquitto.conf:/mosquitto/config/mosquitto.conf:ro
    healthcheck:
      test: ["CMD-SHELL", "mosquitto_sub -h 127.0.0.1 -t test -C 1 -W 2 || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  zookeeper:
    image: zookeeper:3.8
    container_name: zookeeper
    ports: ["2181:2181"]
    restart: unless-stopped

  kafka:
    image: bitnami/kafka:3.7
    container_name: kafka
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
      - ALLOW_PLAINTEXT_LISTENER=yes
    depends_on: [zookeeper]
    ports:
      - "9092:9092"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "/opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 12

  kafka-init:
    image: bitnami/kafka:3.7
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./docker/kafka_streaming/topics.sh:/app/topics.sh:ro
    environment:
      - BOOTSTRAP=kafka:9092
      - KAFKA_BIN=/opt/bitnami/kafka/bin
    entrypoint: ["/bin/bash","-lc","bash /app/topics.sh"]
    restart: "no"


  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka_ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    depends_on: [kafka]
    restart: unless-stopped

  # The bridge containerised
  mqtt_to_kafka:
    build: ./docker/kafka_streaming
    container_name: mqtt_to_kafka
    environment:
      MQTT_BROKER: mqtt
      MQTT_PORT: 1883
      MQTT_TOPIC: ecc/metrics/#
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: metrics.raw.stream
    depends_on: [mqtt, kafka]
    restart: unless-stopped

  # --- MinIO (S3-compatible store for Iceberg) ---
  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    ports: ["9000:9000", "9001:9001"]
    volumes:
      - ./minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 12
    restart: unless-stopped

  # Create the 'warehouse' bucket once
  mc:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: ["/bin/sh","-lc","mc alias set local http://minio:9000 minio minio123 && mc mb -p local/warehouse || true && tail -f /dev/null"]
    restart: unless-stopped


  # --- Flink (SQL) ---
  flink-jobmanager:
    image: flink:1.18
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        rest.address: 0.0.0.0
        rest.port: 8081
        # S3/MinIO for Iceberg
        s3.endpoint: http://minio:9000
        s3.path.style.access: true
        s3.access-key: minio
        s3.secret-key: minio123
        s3.ssl.enabled: false
    ports: ["8081:8081"]
    volumes:
      - ./flink-lib:/opt/flink/custom-lib
      - ./sql:/sql
    restart: unless-stopped

  flink-taskmanager:
    image: flink:1.18
    command: taskmanager
    depends_on: [flink-jobmanager]
    environment:
      - |
        FLINK_PROPERTIES=
        classloader.resolve-order: parent-first
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2

        rest.address: 0.0.0.0
        rest.port: 8081
        pipeline.jars: file:///opt/flink/custom-lib/flink-connector-kafka-3.2.0-1.18.jar,file:///opt/flink/custom-lib/iceberg-flink-runtime-1.5.0.jar,file:///opt/flink/custom-lib/iceberg-aws-bundle-1.5.0.jar

        s3.endpoint: http://minio:9000
        s3.path.style.access: true
        s3.access-key: minio
        s3.secret-key: minio123
        s3.ssl.enabled: false
    volumes:
      - ./flink-lib:/opt/flink/custom-lib
    restart: unless-stopped

  # Run the SQL once (detached) after JM is up
  flink-sql-init:
    image: flink:1.18
    depends_on:
      flink-jobmanager:
        condition: service_started
    volumes:
      - ./flink-lib:/opt/flink/custom-lib
      - ./sql:/sql
    entrypoint: ["/bin/bash", "-lc", "bin/sql-client.sh -f /sql/flink_to_iceberg.sql"]
    restart: "no"
