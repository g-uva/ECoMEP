# üåç Edge-Cloud Continuum Multi-Level Predictive Framework (GreenDIGIT project)

>**Disclaimer**: the information on this README is still temporary. The tools, architecture and other specifications are subject to change.

> Part of GreenDIGIT WP6.2 ‚Äî Predictive AI for Federated Energy-Aware Workflows  
> Developed in collaboration with SoBigData RI, IFCA, DIRAC, and GreenDIGIT RIs and partners.

### To-do
- [ ] Add default remote for data and artefacts; example:
```sh
dvc remote add -d storage gdrive://1n_SyOF_LvzzwqAe6-YPa-PnPR4kvPCE1
dvc push
dvc remote modify storage gdrive_use_service_account true
```
For the moment the data is manually inputted.

This authentication must be somehow integrated with the GCS:
```yaml
steps:
  - uses: actions/checkout@v4
  - uses: iterative/setup-dvc@v1
  - run: dvc pull    # fetch data/model cache
  - run: dvc repro   # fail if pipeline breaks
  - run: dvc metrics show
```
The authentication for the bucket must also be available at Github CI Actions.

---


## Overview

This framework enables **real-time predictive modelling** across **Edge‚ÄìFog‚ÄìCloud infrastructures** using **multi-level machine learning pipelines**. It ingests environmental and performance metrics (e.g. energy, CPU usage, workload profiles) from **distributed clusters and IoT devices**, processes them, and trains models to **forecast resource usage, network load, and system performance**.

Deployed as part of the **GreenDIGIT WP6.2** research activities, this module integrates with:

- [WP6.1 Environmental Metric Publication System](#)
- [WP6.3 Energy-Aware Brokering Framework](#)
- SoBigData RI metrics ecosystem
- IFCA and DIRAC records infrastructure
- (Future plans): Testbed experimentation (e.g., Chamaleon/FABRIC/GD)

---

## Architecture

- [ ] TODO: copy/paste architecture diagram once it's completed.

## Machine Learning Pipeline

### Ingestion & Preprocessing
- Collect metrics from edge nodes, sensors, and cluster logs
- Use **MQTT**, **Prometheus**, or **Kafka/NATS**
- Normalie, timestamp-align, and validate data

### Model Training
- Train using:
  - **Time Series Forecasting** (LSTM, Prophet)
  - **Regression/Classification** (XGBoost, RF)
  - **Energy/Latency Prediction**
- Tools: **PyTorch**, **TensorFlow**, **Scikit-learn**

### Real-Time Inference
- ONNX or TensorFlow Lite models served at edge
- Model registry: MLflow or DVC-based

---

## Folder Structure

<!-- ```bash
.
‚îú‚îÄ‚îÄ ingestion/             # Metric ingestion and connectors
‚îú‚îÄ‚îÄ preprocessing/         # Data cleaning and transformation
‚îú‚îÄ‚îÄ training/              # Training scripts and model tracking
‚îú‚îÄ‚îÄ inference/             # Model serving scripts (ONNX, Lite)
‚îú‚îÄ‚îÄ deployment/            # Helm charts, Dockerfiles
‚îú‚îÄ‚îÄ crate/                 # RO-Crate metadata, licences, schema
‚îú‚îÄ‚îÄ ro-crate-metadata.json
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
``` -->

### New version
```bash
EdgeCloudPredictive/
‚îú‚îÄ‚îÄ ingestion/                # Kafka consumers, schema
‚îú‚îÄ‚îÄ preprocessing/            # Feature builders, GreatExp suites
‚îú‚îÄ‚îÄ training/                 # PyTorch/Sklearn code, MLflow configs
‚îú‚îÄ‚îÄ inference/                # FastAPI server, ONNX / TFLite loaders
‚îú‚îÄ‚îÄ deployment/               # Helm charts, Dockerfiles
‚îÇ   ‚îú‚îÄ‚îÄ helm/                 # Chart for Training & Inference services
‚îÇ   ‚îî‚îÄ‚îÄ gha-workflows/        # CI/CD YAML
‚îú‚îÄ‚îÄ crate/                    # RO-Crate metadata, licences, schema
‚îú‚îÄ‚îÄ ro-crate-metadata.json
‚îî‚îÄ‚îÄ notebooks/                # EDA & experiment design
```

## Outputs and Publications
Unified JSON or RO-Crate formatted metrics

- `/FETCH` endpoint compatible with WP6.1 publication system
- Optionally `POST`ed to:
    - cASO and Grid record services
    - CIM record registry with auth token

### Interoperability
- RO-Crate compliant for FAIR metadata
- Containerised for deployment in federated clusters
- Compatible with SoBigData metrics registry and Dirac grid APIs
- Modular, with pluggable ML models and data formats

## Citation
```
@software{GreenDIGIT_WP62,
  title = {Edge-Cloud Continuum Multi-Level Predictive Framework},
  author = {GreenDIGIT WP6.2 Contributors},
  year = {2025},
  version = {v1.0},
  url = {https://github.com/GreenDIGIT/WP6.2-Predictive-Framework}
}
```

## Contributors
Gon√ßalo Ferreira ‚Äì UvA Researcher - WP6.2 Developer
- [ ] [Collaborators, Partners]

Supported by GreenDIGIT, SoBigData RI, IFCA, DIRAC, and CNR.

## Contact
For questions, integration requests or metric schema definitions, contact:

GreenDIGIT WP6.2 Team
üìß contact@greendigit.eu
üåê greendigit.eu